{"cells":[{"cell_type":"markdown","metadata":{"id":"GPScbsDWhjjS"},"source":["# Data management using Pandas\n","\n","**Data management** is a crucial component to statistical analysis and data science work.\n","\n","This notebook will show you how to import, view, undertand, and manage your data using the [Pandas](http://pandas.pydata.org) data processing library, i.e., the notebook will demonstrates how to read a dataset into Python, and obtain a basic understanding of its content.\n","\n","Note that **Python** by itself is a general-purpose programming language and does not provide high-level data processing capabilities.  The **Pandas** library was developed to meet this need. **Pandas** is the most popular Python library for data manipulation, and we will use it extensively in this course. **Pandas** provides high-performance, easy-to-use data structures and data analysis tools.\n","\n","The main data structure that **Pandas** works with is called a **Data Frame**. This is a two-dimensional table of data in which the rows typically\n","represent cases and the columns represent variables (e.g. data used in this tutorial).  Pandas also has a one-dimensional data structure called a **Series** that we will encounter when accesing a single column of a Data Frame.\n","\n","Pandas has a variety of functions named `read_xxx` for reading data in different formats.  Right now we will focus on reading `csv` files, which stands for comma-separated values. However the other file formats include `excel`, `json`, and `sql`.\n","\n","There are many other options to `read_csv` that are very useful.  For example, you would use the option `sep='\\t'` instead of the default `sep=','` if the fields of your data file are delimited by tabs instead of commas.  See [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) for the full documentation for `read_csv`.\n","\n","\n","## Acknowledgments\n","\n","- The dataset used in this tutorial is from https://www.coursera.org/ from the course \"Understanding and Visualizing Data with Python\" by University of Michigan\n"]},{"cell_type":"markdown","metadata":{"id":"b9FN-daXhjjT"},"source":["# Importing libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRwVhX-YhjjU"},"outputs":[],"source":["# Import the packages that we will be using\n","import pandas as pd\n"]},{"cell_type":"markdown","metadata":{"id":"MbGKgakihjjg"},"source":["# Importing data"]},{"cell_type":"code","source":["# Define where you are running the code: colab or local\n","RunInColab          = True     # (False: no  | True: yes)\n","\n","# If running in colab:\n","if RunInColab:\n","    # Mount your google drive in google colab\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    # Find location\n","    #!pwd\n","    #!ls\n","    #!ls \"/content/drive/My Drive/Colab Notebooks/MachineLearningWithPython/\"\n","\n","    # Define path del proyecto\n","    Ruta            = \"/content/drive/My Drive/Colab Notebooks/MachineLearningWithPython/\"\n","\n","else:\n","    # Define path del proyecto\n","    Ruta            = \"\""],"metadata":{"id":"QIpyBSfdcMjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXHHhj2jhjjg"},"outputs":[],"source":["# url string that hosts our .csv file\n","\n","# Read the .csv file and store it as a pandas Data Frame\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hkKl8GApcJwL"},"source":["If we want to print the information about th output object type we would simply type the following: type(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBSUFAZ7cJwM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"-TrO3YWShjjl"},"source":["# Exploring the content of the data set\n","\n","Use the `shape` method to determine the numbers of rows and columns in a data frame. This can be used to confirm that we have actually obtained the data the we are expecting.\n","\n","Based on what we see below, the data set being read here has $N_r$ rows, corresponding to $N_r$ observations, and $N_c$ columns, corresponding to $N_c$ variables in this particular data file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BOomVZBcJwM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZqxPImzcJwN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CasXmqD6cJwN"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FyCc2caAcJwN"},"source":["If we want to show the entire data frame we would simply write the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clB7ZnfOhjjq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"JxMPJW-OcJwO"},"source":["As you can see, we have a 2-Dimensional object where each row is an independent observation and each coloum is a variable.\n","\n","Now, use the the `head()` function to show the first 5 rows of our data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMgR30w4hjjl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"oiWMoIUrcJwO"},"source":["Also, you can use the the `tail()` function to show the last 5 rows of our data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEBR6g19cJwO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"-F1DVbu4hjju"},"source":["The columns in a Pandas data frame have names, to see the names, use the `columns` method:\n","\n","To gather more information regarding the data, we can view the column names with the following function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEdgVYnDhjjv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"9LxX0C9hcJwP"},"source":["Be aware that every variable in a Pandas data frame has a data type.  There are many different data types, but most commonly you will encounter floating point values (real numbers), integers, strings (text), and date/time values.  When Pandas reads a text/csv file, it guesses the data types based on what it sees in the first few rows of the data file.  Usually it selects an appropriate type, but occasionally it does not.  To confirm that the data types are consistent with what the variables represent, inspect the `dtypes` attribute of the data frame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2aYPe4McJwT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6AGDxEK-cJwW"},"source":["Summary statistics, which include things like the mean, min, and max of the data, can be useful to get a feel for how large some of the variables are and what variables may be the most important."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZjYPS7jcJwZ"},"outputs":[],"source":["# Summary statistics for the quantitative variables\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKA6bMsfcJwb"},"outputs":[],"source":["# Drop observations with NaN values\n","#df.Age.dropna().describe()\n","#df.Wingspan.dropna().describe()"]},{"cell_type":"markdown","metadata":{"id":"1ZvtmKtucJwc"},"source":["It is also possible to get statistics on the entire data frame or a column as follows\n","\n","- `df.mean()` Returns the mean of all columns\n","- `df.corr()` Returns the correlation between columns in a data frame\n","- `df.count()` Returns the number of non-null values in each data frame column\n","- `df.max()` Returns the highest value in each column\n","- `df.min()` Returns the lowest value in each column\n","- `df.median()` Returns the median of each column\n","- `df.std()` Returns the standard deviation of each column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_ZsRJ8ZcJwd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bzUhsRI6cJwe"},"source":["# How to write a data frame to a File\n","\n","To save a file with your data simply use the `to_csv` attribute\n","\n","Examples:\n","- df.to_csv('myDataFrame.csv')\n","- df.to_csv('myDataFrame.csv', sep='\\t')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqh8w6JwcJwg"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QY9GYpGWcJwg"},"source":["# Rename columns\n","\n","To change the name of a colum use the `rename` attribute\n","\n","Example:\n","\n","df = df.rename(columns={\"Age\": \"Edad\"})\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cA09Cmp_cJwh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLwRliQjcJwh"},"outputs":[],"source":["# Back to the original name"]},{"cell_type":"markdown","metadata":{"id":"DNftbkpIcJwi"},"source":["# Selection of colums\n","\n","As discussed above, a Pandas data frame is a rectangular data table, in which the rows represent observations or samples and the columns represent variables.  One common manipulation of a data frame is to extract the data for one case or for one variable.  There are several ways to do this, as shown below.\n","\n","To extract all the values for one column (variable), use one of the following alternatives."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCFrEdLUcJwi"},"outputs":[],"source":["#a = df.Age\n","#b = df[\"Age\"]\n","#c = df.loc[:, \"Age\"]\n","#d = df.iloc[:, 1]\n","\n","#print(d)\n","\n","#df[[\"Gender\", \"GenderGroup\"]]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s0JdLwSZcJwj"},"source":["# Slicing a data set\n","\n","As discussed above, a Pandas data frame is a rectangular data table, in which the rows represent cases and the columns represent variables.  One common manipulation of a data frame is to extract the data for one observation or for one variable.  There are several ways to do this, as shown below.\n","\n","Lets say we would like to splice our data frame and select only specific portions of our data.  There are three different ways of doing so.\n","\n","1. .loc()\n","2. .iloc()\n","3. .ix()\n","\n","We will cover the .loc() and .iloc() splicing functions.\n"]},{"cell_type":"markdown","metadata":{"id":"oeR8lBkmhjjz"},"source":["The attibute **.loc()** uses labels/column names, in specific, it takes two single/list/range operator separated by ',', the first one indicates the rows and the second one indicates columns."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpUEXXovhjj0"},"outputs":[],"source":["# Return all observations of CWDistance\n","#df.loc[:,\"CWDistance\"]\n","\n","# Return a subset of observations of CWDistance\n","#df.loc[:9, \"CWDistance\"]\n","\n","# Select all rows for multiple columns, [\"Gender\", \"GenderGroup\"]\n","#df.loc[:,[\"Gender\", \"GenderGroup\"]]\n","\n","# Select multiple columns, [\"Gender\", \"GenderGroup\"]me\n","#keep = ['Gender', 'GenderGroup']\n","#df_gender = df[keep]\n","\n","# Select few rows for multiple columns, [\"CWDistance\", \"Height\", \"Wingspan\"]\n","#df.loc[4:9, [\"CWDistance\", \"Height\", \"Wingspan\"]]\n","\n","# Select range of rows for all columns\n","#df.loc[10:15,:]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DhluNGL1hjkI"},"source":["The attribute **iloc()** is an integer based slicing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6u1A-2drhjkJ"},"outputs":[],"source":["# .\n","#df.iloc[:, :4]\n","\n","# .\n","#df.iloc[:4, :]\n","\n","# .\n","#df.iloc[:, 3:7]\n","\n","# .\n","#df.iloc[4:8, 2:4]\n","\n","# This is incorrect:\n","#df.iloc[1:5, [\"Gender\", \"GenderGroup\"]]"]},{"cell_type":"markdown","metadata":{"id":"u4ORG1PlcJwl"},"source":["# Get unique existing values\n","\n","List unique values in the one of the columns\n","\n","df.Gender.unique()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brIC2kbKhjkZ"},"outputs":[],"source":["# List unique values in the df['Gender'] column\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Js4ikCVWhjkc"},"outputs":[],"source":["# Lets explore df[\"GenderGroup] as well\n"]},{"cell_type":"markdown","metadata":{"id":"n0S7vCwphjkj"},"source":["# Filter, Sort and Groupby\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yTtJ3JKFcJwn"},"source":["With **Filter** you can use different conditions to filter columns. For example, df[df[year] > 1984] would give you only the column year is greater than 1984. You can use & (and) or | (or) to add different conditions to your filtering. This is also called boolean filtering.\n","\n","df[df[\"Height\"] >= 70]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATi54wH_cJwo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LR5TNojlcJwq"},"source":["With **Sort** is possible to sort values in a certain column in an ascending order using `df.sort_values(\"ColumnName\")` or in descending order using `df.sort_values(ColumnName, ascending=False)`.\n","\n","Furthermore, it’s possible to sort values by Column1Name in ascending order then Column2Name in descending order by using `df.sort_values([Column1Name,Column2Name],ascending=[True,False])`\n","\n","\n","df.sort_values(\"Height\")\n","#df.sort_values(\"Height\",ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJCVsL3fcJwq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jzSIpt_8cJwr"},"source":["The attribute **Groupby** involves splitting the data into groups based on some criteria, applying a function to each group independently and combining the results into a data structure. df.groupby(col) returns a groupby object for values from one column while df.groupby([col1,col2]) returns a groupby object for values from multiple columns.\n","\n","df.groupby(['Gender'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvIXfwC5cJwr"},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"nTRCVyPhcJwr"},"source":["Size of each group\n","\n","df.groupby(['Gender']).size()\n","\n","df.groupby(['Gender','GenderGroup']).size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNvUQetJhjkj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7bHLzOH2hjkn"},"source":["This output indicates that we have two types of combinations.\n","\n","* Case 1: Gender = F & Gender Group = 1\n","* Case 2: Gender = M & GenderGroup = 2.  \n","\n","This validates our initial assumption that these two fields essentially portray the same information."]},{"cell_type":"markdown","metadata":{"id":"eWlEBPtscJws"},"source":["# Data Cleaning: handle with missing data\n","\n","Before getting started to work with your data, it's a good practice to observe it thoroughly to identify missing values and handle them accordingly.\n","\n","When reading a dataset using Pandas, there is a set of values including 'NA', 'NULL', and 'NaN' that are taken by default to represent a missing value.  The full list of default missing value codes is in the '`read_csv`' documentation [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).  This document also explains how to change the way that '`read_csv`' decides whether a variable's value is missing.\n","\n","Pandas has functions called `isnull` and `notnull` that can be used to identify where the missing and non-missing values are located in a data frame.  \n","\n","Below we use these functions to count the number of missing and non-missing values in each variable of the datasetr."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZsVRoHacJws"},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"ON2BW-VPcJwt"},"source":["Unfortunately, our output indicates that some of our columns contain missing values so we are no able to continue on doing analysis with those colums"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7I67YNTcJwt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGajtmWfcJwt"},"outputs":[],"source":["#df.isnull().sum()\n","#df.notnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"e-oY7TFccJwt"},"source":["Now we use these functions to count the number of missing and non-missing values in a single variable in the dataset\n","\n","print( df.Height.notnull().sum() )\n","\n","print( pd.isnull(df.Height).sum() )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcXbjV3rcJwu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4IDFNQncJwu"},"outputs":[],"source":["# Extract all non-missing values of one of the columns into a new variable\n","#x = df.Age.dropna().describe()\n","#x.describe()"]},{"cell_type":"markdown","metadata":{"id":"PcbsqjI6cJwu"},"source":["# Add and eliminate columns\n","\n","In some cases it is useful to create or eiminate new columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXL2cnn0cJwu"},"outputs":[],"source":["#df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFjBasJacJwu"},"outputs":[],"source":["# Add a new column with new data\n","\n","# Create a column data\n","#NewColumnData = df.Age/df.Age\n","\n","# Insert that column in the data frame\n","#df.insert(12, \"ColumnInserted\", NewColumnData, True)\n","\n","#df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AY1Xf0PcJwv"},"outputs":[],"source":["# # Eliminate inserted column\n","# df.drop(\"ColumnInserted\", axis=1, inplace = True)\n","# #df.drop(columns=['ColumnInserted'], inplace = True)\n","# # Remove three columns as index base\n","# #df.drop(df.columns[[12]], axis = 1, inplace = True)\n","#\n","# df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVJVlUR2cJwv"},"outputs":[],"source":["# # Add new column derived from existing columns\n","#\n","# # The new column is a function of another column\n","# df[\"AgeInMonths\"] = df[\"Age\"] * 12\n","#\n","# df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8FJvHsQcJwv"},"outputs":[],"source":["# # Eliminate inserted column\n","# df.drop(\"AgeInMonths\", axis=1, inplace = True)\n","#\n","# df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRKPB77mcJww"},"outputs":[],"source":["# Add a new column with text labels reflecting the code's meaning\n","\n","# df[\"GenderGroupNew\"] = df.GenderGroup.replace({1: \"Female\", 2: \"Male\"})\n","\n","# Show the first 5 rows of the created data frame\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aQx04JrcJww"},"outputs":[],"source":["## Eliminate inserted column\n","# df.drop(\"GenderGroupNew\", axis=1, inplace = True)\n","##df.drop(['GenderGroupNew'],vaxis='columns',vinplace=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDRFjGPgcJwx"},"outputs":[],"source":["## Add a new column with strata based on these cut points\n","#\n","## Create a column data\n","#NewColumnData = df.Age/df.Age\n","#\n","## Insert that column in the data frame\n","#df.insert(1, \"ColumnStrata\", NewColumnData, True)\n","#\n","#df[\"ColumnStrata\"] = pd.cut(df.Height, [60., 63., 66., 69., 72., 75., 78.])\n","#\n","## Show the first 5 rows of the created data frame\n","#df.head()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92xxpyXYcJwy"},"outputs":[],"source":["## Eliminate inserted column\n","#df.drop(\"ColumnStrata\", axis=1, inplace = True)\n","#\n","#df.head()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuA1GyJlcJw0"},"outputs":[],"source":["# Drop several \"unused\" columns\n","#vars = [\"ID\", \"GenderGroup\", \"GlassesGroup\", \"CompleteGroup\"]\n","#df.drop(vars, axis=1, inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"FJhET6apcJw3"},"source":["# Add and eliminate rows\n","\n","In some cases it is requiered to add new observations (rows) to the data set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkVVZL79cJw4"},"outputs":[],"source":["# Print tail\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xpEkmQmcJw5"},"outputs":[],"source":["#df.loc[len(df.index)] = [26, 24, 'F', 1, 'Y', 1, 66, 'NaN', 68, 'N', 0, 3]\n","#\n","#df.tail()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4j5bL6hcJw5"},"outputs":[],"source":["## Eliminate inserted row\n","#df.drop([28], inplace = True )\n","#\n","#df.tail()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E7cXjrR5cJw6"},"source":["# Cleaning your data: drop out unused columns and/or drop out rows with any missing values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8n-Cq_kycJw6"},"outputs":[],"source":["# Drop unused columns\n","#vars = [\"ID\", \"GenderGroup\", \"GlassesGroup\", \"CompleteGroup\"]\n","#df.drop(vars, axis=1, inplace = True)\n","\n","#vars = [\"Age\", \"Gender\", \"Glasses\", \"Height\", \"Wingspan\", \"CWDistance\", \"Complete\", \"Score\"]\n","#df = df[vars]\n","\n","# Drop rows with any missing values\n","#df = df.dropna()\n","\n","# Drop unused columns and drop rows with any missing values\n","#vars = [\"Age\", \"Gender\", \"Glasses\", \"Height\", \"Wingspan\", \"CWDistance\", \"Complete\", \"Score\"]\n","#df = df[vars].dropna()\n","\n","#df\n"]},{"cell_type":"markdown","metadata":{"id":"xtbam6vHcJw6"},"source":["# Final remarks\n","\n","\n","- The understanding of your dataset is essential\n","    - Number of observations\n","    - Variables\n","    - Data types: numerical or categorial\n","    - What are my variables of interest\n","\n","- There are several ways to do the same thing\n","\n","- Cleaning your dataset (dropping out rows with any missing values) is a good practice\n","\n","- The **Pandas** library provides fancy, high-performance, easy-to-use data structures and data analysis tools\n"]},{"cell_type":"markdown","metadata":{"id":"aKzAqogCcJw7"},"source":["# Activity: work with the iris dataset\n","\n","Repeat this tutorial with the iris data set and respond to the following inquiries\n","\n","1. Calculate the statistical summary for each quantitative variables. Explain the results\n","    - Identify the name of each column\n","    - Identify the type of each column\n","    - Minimum, maximum, mean, average, median, standar deviation\n","    \n","    \n","2. Are there missing data? If so, create a new dataset containing only the rows with the non-missing data\n","\n","\n","3. Create a new dataset containing only the petal width and length and the type of Flower\n","\n","\n","4. Create a new dataset containing only the setal width and length and the type of Flower\n","\n","\n","5. Create a new dataset containing the setal width and length and the type of Flower encoded as a categorical numerical column\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1tW9Q-fdcJw7"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}